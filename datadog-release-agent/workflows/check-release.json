{
  "objective": "Validate a release by comparing telemetry data before and after for a specified service_name and release_time.\n\n",
  "steps": "## Part 1: **Define Windows**\n•\tPre: [release_time - N, release_time)\n•\tPost: [release_time, release_time + N)\n## Part 2: **Log Analysis**\n`Severity`\n\t•\tWARN+ if level/status ∈ {warn, warning, error, fatal, critical}\n\t•\tERROR+ if level/status ∈ {error, fatal, critical}\n1) Total logs\n\t•\ttotal_pre = count(logs(service_name, pre))\n\t•\ttotal_post = count(logs(service_name, post))\n2) WARN+ logs\n\t•\twarn_pre = count(WARN+ logs in pre)\n\t•\twarn_post = count(WARN+ logs in post)\n3) WARN+ rate regression (percentage points)\n\t•\t`pct_pre` = `(warn_pre/total_pre)*100 (0 if total_pre==0)`\n\t•\t`pct_post` = `(warn_post/total_post)*100 (0 if total_post==0)`\n\t•\t`delta_pp` = `pct_post - pct_pre`\n\t•\t`warn_regression` = `(total_pre>0 && total_post>0 && warn_post>=1 && delta_pp >= threshold_pp)`\n4) Stopped patterns (any severity)\n\t•\tCheck if any INFO patterns stopped all together post-release and were happening frequently before. \n5) New error patterns (true errors only)\n\t•\tCheck if any WARN+ patterns started happening only post-release and were NOT happening before.\n## Part 3: Metrics Analysis\n1. Find system metrics (`CPU`, `Memory`, `Network`, `Disk`) and compare before and after release\n2. Check error metrics for sustained increases post-release\n3. Check latency metrics for sustained increases post-release\n4. For custom metrics, identify critical tags, group by them, and compare pre vs post values\n## Output Format\n- **ALWAYS** provide a thumbs up or thumbs down on slack to #general for the release\n- If thumbs down, provide a summary section for each issue type:\n  - **Log Issues**: List in tabular form: pattern description, example log line, pre vs post counts, why it matters?\n  - **Metric Issues**: List in tabular form: metric name, pre vs post comparison, why this change matters?",
  "guardrails": "### Log Analysis Thresholds\n- Flag if `WARN+` log levels increase by **more than 20%** post-release\n- Flag patterns that disappeared entirely post-release\n- Flag new error patterns that appeared post-release\n### Metrics Analysis Thresholds\n- Flag if `P50` or `P99` from the (execute metrics tool output) post-release has moved at least **1.5x** compared to pre-release\n- Direction of movement should be contextual: increases in errors/latency are bad, decreases in requests are bad\n### Output Format Instructions\n- Post **exactly one** Slack message to Ruchir.\n- The message must contain **only Blockit grids** (no prose, no bullets, no extra commentary).\n- Always include a **Verdict Grid**. Include **Log Issues Grid** only if there are log flags. Include **Metric Issues Grid** only if there are metric flags. If no issues for a section, omit that grid entirely.\n#### Grid 1: Verdict (ALWAYS)\nColumns (exact):\n- `Verdict` (\uD83D\uDC4D or \uD83D\uDC4E)\n- `Service`\n- `Release Time`\n- `Window`\n- `WARN+ % Pre`\n- `WARN+ % Post`\n- `Delta (pp)`\n- `Threshold (pp)`\n- `WARN+ Regression` (PASS/FAIL)\nRules:\n- `WARN+ %` values must be rounded to 2 decimals.\n- `Delta (pp) = WARN+ % Post - WARN+ % Pre`, rounded to 2 decimals.\n- `WARN+ Regression = FAIL` iff `warn_regression == true`, else `PASS`.\n#### Grid 2: Log Issues (ONLY if any log guardrail flagged)\nColumns (exact):\n- `Issue`\n- `Pattern`\n- `Example`\n- `Pre Count`\n- `Post Count`\n- `Why it matters`\nRules:\n- `Issue` must be one of: `WARN+ Regression`, `Stopped Pattern`, `New Error Pattern`.\n- For `New Error Pattern`, only include patterns from **ERROR+ logs** (not INFO/WARN).\n- `Example` must be a single trimmed log line (max 140 chars).\n#### Grid 3: Metric Issues (ONLY if any metric guardrail flagged)\nColumns (exact):\n- `Metric`\n- `Scope` (Overall or tag breakdown label)\n- `Pre`\n- `Post`\n- `Change`\n- `Threshold`\n- `Why it matters`\nRules:\n- `Change` must be formatted as `+X%` / `-X%` (rounded to 1 decimal) or `x1.5` style for latency ratios.\n- `Threshold` must match the guardrail that triggered (e.g., `>=1.5x`, `>=20%`).\n- Include **only** metrics that triggered a guardrail.\n#### Ordering\n- Verdict grid first.\n- Log Issues grid second (if present), sorted by severity: `WARN+ Regression` then `New Error Pattern` then `Stopped Pattern`.\n- Metric Issues grid last (if present), sorted: errors → latency → requests → system.\n#### Hard constraint\n- Do not output any non-Blockit text in Slack.",
  "reports": [
    "service-logs-search",
    "service-logs-retrieval",
    "service-request-count",
    "service-request-count-by-dimension",
    "service-error-count",
    "service-error-count-by-dimension",
    "service-error-rate",
    "service-latency-percentiles",
    "http-request-duration-average",
    "http-duration-by-status",
    "average-http-request-duration",
    "server-request-count",
    "client-requests-by-server"
  ],
  "knowledge": [],
  "trigger": "schedule",
  "schedule": "0 0 * * *"
}
